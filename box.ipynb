{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_speaker = False\n",
    "filename = \"combined_smaller_sample_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_file(filepath):\n",
    "    \"\"\"\n",
    "    Reads a JSON file and returns the data as a Python object.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict or list: The data from the JSON file, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in {filepath}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'speakers': [{'speaker': 'SPEAKER_01', 'text': ' Yet, he is of all creatures the most formatively armed.', 'timestamp': [0.0, 4.52]}, {'speaker': 'SPEAKER_00', 'text': ' What then is the devilfish? It is the sea vampire.', 'timestamp': [4.52, 9.24]}, {'speaker': 'SPEAKER_02', 'text': ' To make sure this sad part of my story, we went the way of Hall sailors. The punch was made and I was made half drunk with it.', 'timestamp': [9.24, 18.04]}, {'speaker': 'SPEAKER_01', 'text': \" At about two o'clock we heard the loud cry of sailho from a loft.\", 'timestamp': [18.04, 23.4]}], 'asr': {'text': \" Yet, he is of all creatures the most formatively armed. What then is the devilfish? It is the sea vampire. To make sure this sad part of my story, we went the way of Hall sailors. The punch was made and I was made half drunk with it. At about two o'clock we heard the loud cry of sailho from a loft.\", 'chunks': [{'timestamp': [0.0, 4.52], 'text': ' Yet, he is of all creatures the most formatively armed.'}, {'timestamp': [4.52, 6.44], 'text': ' What then is the devilfish?'}, {'timestamp': [6.44, 9.24], 'text': ' It is the sea vampire.'}, {'timestamp': [9.24, 14.24], 'text': ' To make sure this sad part of my story, we went the way of Hall sailors.'}, {'timestamp': [14.24, 18.04], 'text': ' The punch was made and I was made half drunk with it.'}, {'timestamp': [18.04, 23.4], 'text': \" At about two o'clock we heard the loud cry of sailho from a loft.\"}]}, 'diarization': [{'segment': {'start': 0.45284375, 'end': 0.5372187500000001}, 'track': 'A', 'label': 'SPEAKER_01'}, {'segment': {'start': 0.5372187500000001, 'end': 8.02971875}, 'track': 'B', 'label': 'SPEAKER_00'}, {'segment': {'start': 9.160343750000003, 'end': 9.177218750000002}, 'track': 'C', 'label': 'SPEAKER_00'}, {'segment': {'start': 9.177218750000002, 'end': 17.36159375}, 'track': 'D', 'label': 'SPEAKER_02'}, {'segment': {'start': 17.98596875, 'end': 23.43659375}, 'track': 'E', 'label': 'SPEAKER_01'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = read_json_file(f'output/{filename}.json')\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segments [{'segment': {'start': 0.45284375, 'end': 0.5372187500000001}, 'track': 'A', 'label': 'SPEAKER_01'}, {'segment': {'start': 0.5372187500000001, 'end': 8.02971875}, 'track': 'B', 'label': 'SPEAKER_00'}, {'segment': {'start': 9.160343750000003, 'end': 9.177218750000002}, 'track': 'C', 'label': 'SPEAKER_00'}, {'segment': {'start': 9.177218750000002, 'end': 17.36159375}, 'track': 'D', 'label': 'SPEAKER_02'}, {'segment': {'start': 17.98596875, 'end': 23.43659375}, 'track': 'E', 'label': 'SPEAKER_01'}]\n",
      "new_segments [{'segment': {'start': 0.45284375, 'end': 0.5372187500000001}, 'speaker': 'SPEAKER_01'}, {'segment': {'start': 0.5372187500000001, 'end': 9.177218750000002}, 'speaker': 'SPEAKER_00'}, {'segment': {'start': 9.177218750000002, 'end': 17.98596875}, 'speaker': 'SPEAKER_02'}, {'segment': {'start': 17.98596875, 'end': 23.43659375}, 'speaker': 'SPEAKER_01'}]\n"
     ]
    }
   ],
   "source": [
    "segments = json_data[\"diarization\"]\n",
    "print(\"segments\", segments)\n",
    "\n",
    "# diarizer output may contain consecutive segments from the same speaker (e.g. {(0 -> 1, speaker_1), (1 -> 1.5, speaker_1), ...})\n",
    "# we combine these segments to give overall timestamps for each speaker's turn (e.g. {(0 -> 1.5, speaker_1), ...})\n",
    "new_segments = []\n",
    "prev_segment = cur_segment = segments[0]\n",
    "\n",
    "for i in range(1, len(segments)):\n",
    "    cur_segment = segments[i]\n",
    "\n",
    "    # check if we have changed speaker (\"label\")\n",
    "    if cur_segment[\"label\"] != prev_segment[\"label\"] and i < len(segments):\n",
    "        # add the start/end times for the super-segment to the new list\n",
    "        new_segments.append(\n",
    "            {\n",
    "                \"segment\": {\"start\": prev_segment[\"segment\"][\"start\"], \"end\": cur_segment[\"segment\"][\"start\"]},\n",
    "                \"speaker\": prev_segment[\"label\"],\n",
    "            }\n",
    "        )\n",
    "        prev_segment = segments[i]\n",
    "\n",
    "# add the last segment(s) if there was no speaker change\n",
    "new_segments.append(\n",
    "    {\n",
    "        \"segment\": {\"start\": prev_segment[\"segment\"][\"start\"], \"end\": cur_segment[\"segment\"][\"end\"]},\n",
    "        \"speaker\": prev_segment[\"label\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"new_segments\", new_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': [0.0, 4.52], 'text': ' Yet, he is of all creatures the most formatively armed.'}, {'timestamp': [4.52, 6.44], 'text': ' What then is the devilfish?'}, {'timestamp': [6.44, 9.24], 'text': ' It is the sea vampire.'}, {'timestamp': [9.24, 14.24], 'text': ' To make sure this sad part of my story, we went the way of Hall sailors.'}, {'timestamp': [14.24, 18.04], 'text': ' The punch was made and I was made half drunk with it.'}, {'timestamp': [18.04, 23.4], 'text': \" At about two o'clock we heard the loud cry of sailho from a loft.\"}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "transcript = json_data[\"asr\"][\"chunks\"]\n",
    "print(\"transcript\", transcript)\n",
    "\n",
    "# get the end timestamps for each chunk from the ASR output\n",
    "end_timestamps = np.array([chunk[\"timestamp\"][-1] for chunk in transcript])\n",
    "segmented_preds = []\n",
    "\n",
    "# align the diarizer timestamps and the ASR timestamps\n",
    "for segment in new_segments:\n",
    "    # get the diarizer end timestamp\n",
    "    end_time = segment[\"segment\"][\"end\"]\n",
    "    # find the ASR end timestamp that is closest to the diarizer's end timestamp and cut the transcript to here\n",
    "    try:\n",
    "        upto_idx = np.argmin(np.abs(end_timestamps - end_time))\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    if group_by_speaker:\n",
    "        segmented_preds.append(\n",
    "            {\n",
    "                \"speaker\": segment[\"speaker\"],\n",
    "                \"text\": \"\".join([chunk[\"text\"] for chunk in transcript[: upto_idx + 1]]),\n",
    "                \"timestamp\": (transcript[0][\"timestamp\"][0], transcript[upto_idx][\"timestamp\"][1]),\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        for i in range(upto_idx + 1):\n",
    "            segmented_preds.append({\"speaker\": segment[\"speaker\"], **transcript[i]})\n",
    "\n",
    "    # crop the transcripts and timestamp lists according to the latest timestamp (for faster argmin)\n",
    "    transcript = transcript[upto_idx + 1 :]\n",
    "    end_timestamps = end_timestamps[upto_idx + 1 :]\n",
    "\n",
    "print(segmented_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
